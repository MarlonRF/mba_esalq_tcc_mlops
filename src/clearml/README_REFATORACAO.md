# RefatoraÃ§Ã£o da Estrutura ClearML

## ğŸ“ Nova Estrutura Modular

```
src/clearml/
â”œâ”€â”€ utils/                              # FunÃ§Ãµes auxiliares modulares
â”‚   â”œâ”€â”€ __init__.py                    # Exports principais
â”‚   â”œâ”€â”€ verificador_clearml.py         # Verifica disponibilidade ClearML
â”‚   â”œâ”€â”€ operacoes_task.py              # Criar e gerenciar tasks
â”‚   â”œâ”€â”€ operacoes_dataset.py           # Criar e gerenciar datasets
â”‚   â””â”€â”€ integracao_artefatos.py        # Registrar artefatos (DataFrames, mÃ©tricas)
â”‚
â””â”€â”€ pipelines_clearml/                  # Pipelines integrados com ClearML
    â”œâ”€â”€ __init__.py
    â””â”€â”€ pipeline_processamento_clearml.py  # Pipeline de processamento
```

## ğŸ¯ PrincÃ­pios da RefatoraÃ§Ã£o

### 1. **ModularizaÃ§Ã£o**
- Cada funÃ§Ã£o auxiliar em seu prÃ³prio mÃ³dulo
- SeparaÃ§Ã£o clara de responsabilidades
- Facilita manutenÃ§Ã£o e testes

### 2. **Nomenclatura em PortuguÃªs**
- Todas as funÃ§Ãµes, variÃ¡veis e mÃ³dulos em portuguÃªs
- ConsistÃªncia com domÃ­nio do projeto
- Facilita compreensÃ£o do cÃ³digo

### 3. **ReutilizaÃ§Ã£o de Pipelines Locais**
- Pipelines ClearML sÃ£o wrappers
- LÃ³gica de negÃ³cio permanece em `src/pipelines/`
- ClearML adiciona apenas rastreamento e versionamento

### 4. **Simplicidade Incremental**
- ComeÃ§ar simples e adicionar funcionalidades gradualmente
- Pipeline de processamento como primeiro exemplo
- Base sÃ³lida para features e treinamento

## ğŸ“¦ MÃ³dulos Utils

### `verificador_clearml.py`
Verifica se ClearML estÃ¡ disponÃ­vel e instalado.

**FunÃ§Ãµes:**
- `obter_clearml_disponivel()` - Retorna True se ClearML disponÃ­vel
- `garantir_clearml_disponivel()` - Decorator para funÃ§Ãµes que usam ClearML

### `operacoes_task.py`
OperaÃ§Ãµes bÃ¡sicas com Tasks ClearML.

**FunÃ§Ãµes:**
- `criar_task()` - Cria nova task
- `obter_task_atual()` - Retorna task em execuÃ§Ã£o

### `operacoes_dataset.py`
OperaÃ§Ãµes bÃ¡sicas com Datasets ClearML.

**FunÃ§Ãµes:**
- `criar_dataset()` - Cria novo dataset versionado
- `buscar_dataset()` - Busca dataset por nome ou ID

### `integracao_artefatos.py`
Registra artefatos no ClearML.

**FunÃ§Ãµes:**
- `registrar_dataframe()` - Registra DataFrame
- `registrar_metricas()` - Registra mÃ©tricas (dict)
- `registrar_arquivo()` - Registra arquivo qualquer

## ğŸ”„ Pipeline de Processamento

### Arquitetura

```python
executar_pipeline_processamento_clearml()
    â”‚
    â”œâ”€> [ClearML] criar_task()
    â”‚   â””â”€> Rastrear configuraÃ§Ãµes
    â”‚
    â”œâ”€> [Pipeline Local] executar_pipeline_processamento()
    â”‚   â””â”€> src/pipelines/pipeline_processamento.py
    â”‚       â”œâ”€> Carregar dados
    â”‚       â”œâ”€> Limpeza
    â”‚       â”œâ”€> TransformaÃ§Ãµes
    â”‚       â””â”€> Retorna DataFrame
    â”‚
    â””â”€> [ClearML] Registrar Resultados
        â”œâ”€> registrar_dataframe()
        â”œâ”€> registrar_metricas()
        â””â”€> criar_dataset() versionado
```

### Uso

```python
from src.clearml.pipelines_clearml import executar_pipeline_processamento_clearml

# Modo online (com ClearML)
resultado = executar_pipeline_processamento_clearml(
    caminho_csv="dados/arquivo.csv",
    offline_mode=False
)

# Modo offline (sem ClearML)
resultado = executar_pipeline_processamento_clearml(
    caminho_csv="dados/arquivo.csv",
    offline_mode=True
)

# Acessar resultados
df = resultado["dados_processados"]
shape = resultado["shape"]
dataset_id = resultado["dataset_id"]  # None se offline
```

### ExecuÃ§Ã£o Direta

```bash
# Com ClearML
python src/clearml/pipelines_clearml/pipeline_processamento_clearml.py

# Sem ClearML
python src/clearml/pipelines_clearml/pipeline_processamento_clearml.py --offline

# Arquivo customizado
python src/clearml/pipelines_clearml/pipeline_processamento_clearml.py dados/meu_arquivo.csv
```

## ğŸ“ Arquivos Legados

Arquivos antigos foram renomeados com extensÃ£o `.py_old`:
- `pipeline_01_processamento.py_old` - VersÃ£o antiga do pipeline de processamento
- `pipeline_02_features.py_old` - VersÃ£o antiga do pipeline de features

**AÃ§Ã£o recomendada:** Manter por perÃ­odo de transiÃ§Ã£o, depois remover.

## ğŸ¨ Pipeline de Features

### Arquitetura

```python
executar_pipeline_features_clearml()
    â”‚
    â”œâ”€> [ClearML] criar_task()
    â”‚   â””â”€> Rastrear configuraÃ§Ãµes e dataset pai
    â”‚
    â”œâ”€> [Pipeline Local] executar_pipeline_features()
    â”‚   â””â”€> src/pipelines/pipeline_features.py
    â”‚       â”œâ”€> Features derivadas (IMC, heat index, etc)
    â”‚       â”œâ”€> CodificaÃ§Ã£o categÃ³rica (label/onehot)
    â”‚       â”œâ”€> NormalizaÃ§Ã£o (standard/minmax/robust)
    â”‚       â””â”€> Retorna DataFrame + artefatos
    â”‚
    â””â”€> [ClearML] Registrar Resultados
        â”œâ”€> registrar_dataframe()
        â”œâ”€> registrar_arquivo() para artefatos (mapeamentos)
        â”œâ”€> registrar_metricas()
        â””â”€> criar_dataset() versionado com parent_id
```

### Uso

```python
from src.clearml.pipelines_clearml import executar_pipeline_features_clearml

# Modo online (com ClearML)
resultado = executar_pipeline_features_clearml(
    df_processado=df,
    dataset_processado_id="abc123",  # ID do dataset anterior
    offline_mode=False,
    criar_features_derivadas=True,
    aplicar_codificacao=True,
    aplicar_normalizacao=True
)

# Modo offline (sem ClearML)
resultado = executar_pipeline_features_clearml(
    df_processado=df,
    offline_mode=True
)

# Acessar resultados
df_features = resultado["dados_features"]
artefatos = resultado["artefatos"]  # Mapeamentos, colunas criadas
dataset_id = resultado["dataset_id"]  # None se offline
```

### ExecuÃ§Ã£o Direta

```bash
# Com ClearML
python src/clearml/pipelines_clearml/pipeline_features_clearml.py

# Sem ClearML
python src/clearml/pipelines_clearml/pipeline_features_clearml.py --offline
```

## ğŸš€ PrÃ³ximos Passos

1. **Pipeline de Features** âœ… **CONCLUÃDO**
   - `pipeline_features_clearml.py` âœ…
   - Reutiliza `src/pipelines/pipeline_features.py` âœ…
   - Registra features derivadas, encoders e mapeamentos âœ…

2. **Pipeline de Treinamento** ğŸ“‹ Planejado
   - `pipeline_treinamento_clearml.py`
   - Reutilizar `src/pipelines/pipeline_treinamento.py`
   - Registrar modelos e mÃ©tricas

3. **Pipeline Completo** ğŸ“‹ Planejado
   - Orquestrar os 3 pipelines
   - Usar PipelineDecorator para componentes
   - Versionamento automÃ¡tico entre etapas

## ğŸ’¡ BenefÃ­cios

âœ… **Manutenibilidade**: Cada funÃ§Ã£o em seu prÃ³prio arquivo  
âœ… **Testabilidade**: MÃ³dulos independentes fÃ¡ceis de testar  
âœ… **Clareza**: Nomenclatura em portuguÃªs consistente  
âœ… **Flexibilidade**: Modo online/offline configurÃ¡vel  
âœ… **ReutilizaÃ§Ã£o**: LÃ³gica de negÃ³cio separada de rastreamento  
âœ… **Escalabilidade**: Base sÃ³lida para adicionar mais pipelines  

## ğŸ“– ReferÃªncias

- **ConfiguraÃ§Ãµes**: `config/config_custom.py`, `config/config_clearml.py`
- **Pipeline Local**: `src/pipelines/pipeline_processamento.py`
- **DocumentaÃ§Ã£o ClearML**: https://clear.ml/docs
