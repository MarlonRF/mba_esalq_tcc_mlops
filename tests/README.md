# ğŸ§ª Estrutura de Testes - MLOps Pipeline

Este diretÃ³rio contÃ©m todos os testes do projeto, organizados em **testes unitÃ¡rios** e **testes de integraÃ§Ã£o**.

## ğŸ“ Estrutura

```
tests/
â”œâ”€â”€ unit/                          # Testes unitÃ¡rios (isolados, rÃ¡pidos)
â”‚   â”œâ”€â”€ api/                      # Testes da API
â”‚   â”œâ”€â”€ features/                 # Testes de engenharia de features
â”‚   â”‚   â”œâ”€â”€ codificacao/         # One-hot, label encoding, etc.
â”‚   â”‚   â”œâ”€â”€ criacao_features/    # IMC, heat index, etc.
â”‚   â”‚   â””â”€â”€ normalizacao/        # Standard, MinMax, Robust scalers
â”‚   â”œâ”€â”€ pipelines/               # Testes dos pipelines principais
â”‚   â”œâ”€â”€ processamento/           # Testes de processamento de dados
â”‚   â”‚   â”œâ”€â”€ imputacao/          # ImputaÃ§Ã£o de valores faltantes
â”‚   â”‚   â”œâ”€â”€ limpeza/            # Limpeza e conversÃ£o de tipos
â”‚   â”‚   â””â”€â”€ temporal/           # Processamento temporal
â”‚   â”œâ”€â”€ treinamento/            # Testes de treinamento ML
â”‚   â”‚   â”œâ”€â”€ avaliacao/         # AvaliaÃ§Ã£o de modelos
â”‚   â”‚   â”œâ”€â”€ configuracao/      # Setup e configuraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ persistencia/      # Salvar/carregar modelos
â”‚   â”‚   â”œâ”€â”€ treino/            # Treino, otimizaÃ§Ã£o, finalizaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ utils/             # Utilidades de treinamento
â”‚   â”‚   â””â”€â”€ visualizacao/      # Plots e visualizaÃ§Ãµes
â”‚   â””â”€â”€ utils/                  # Testes de utilidades gerais
â”‚       â”œâ”€â”€ io/                # I/O local e ClearML
â”‚       â”œâ”€â”€ clearml/           # IntegraÃ§Ã£o ClearML
â”‚       â””â”€â”€ dados_sinteticos/  # GeraÃ§Ã£o de dados sintÃ©ticos
â”‚
â”œâ”€â”€ integration/                 # Testes de integraÃ§Ã£o (end-to-end)
â”‚   â”œâ”€â”€ test_pipeline_end_to_end.py          # Fluxo completo
â”‚   â”œâ”€â”€ test_cenarios_reais.py               # CenÃ¡rios com dados reais
â”‚   â”œâ”€â”€ test_pipeline_unificado.py           # Pipeline unificado
â”‚   â”œâ”€â”€ test_treinamento_pipeline.py         # Pipeline de treinamento
â”‚   â””â”€â”€ test_pipeline_processamento_integration.py  # Pipeline processamento
â”‚
â”œâ”€â”€ conftest.py                  # Fixtures compartilhadas
â””â”€â”€ README.md                    # Este arquivo
```

## ğŸ¯ Tipos de Testes

### Testes UnitÃ¡rios (`tests/unit/`)

**Objetivo**: Testar funÃ§Ãµes e mÃ³dulos **isoladamente**, com foco em velocidade.

**CaracterÃ­sticas**:
- âœ… RÃ¡pidos (< 1 segundo cada)
- âœ… Testam uma Ãºnica funÃ§Ã£o/classe
- âœ… Usam mocks e dados sintÃ©ticos
- âœ… Sem dependÃªncias externas (banco de dados, APIs, etc.)

**ConvenÃ§Ã£o de nomenclatura**:
```
src/{modulo}/{arquivo}.py  â†’  tests/unit/{modulo}/test_{arquivo}.py
```

**Exemplo**:
```python
# src/features/normalizacao/normalizar.py
def normalizar_dados(df, metodo='standard'):
    ...

# tests/unit/features/normalizacao/test_normalizar.py
def test_normalizar_dados_metodo_standard():
    df = pd.DataFrame({'col1': [1, 2, 3]})
    resultado = normalizar_dados(df, metodo='standard')
    assert resultado['col1'].mean() < 0.01  # MÃ©dia ~0
```

### Testes de IntegraÃ§Ã£o (`tests/integration/`)

**Objetivo**: Testar **interaÃ§Ã£o entre mÃºltiplos mÃ³dulos** e fluxos completos.

**CaracterÃ­sticas**:
- â±ï¸ Mais lentos (vÃ¡rios segundos/minutos)
- ğŸ”— Testam fluxos end-to-end
- ğŸ“Š Usam dados reais ou realistas
- âœ… Validam integraÃ§Ã£o entre pipelines

**Principais arquivos**:

#### 1. `test_pipeline_end_to_end.py`
Testa o fluxo completo do MLOps:
- âœ… Processamento â†’ Features â†’ Treinamento
- âœ… ClassificaÃ§Ã£o e RegressÃ£o
- âœ… Com e sem otimizaÃ§Ã£o de hiperparÃ¢metros
- âœ… ConsistÃªncia de dados atravÃ©s do pipeline

```python
# Exemplo de teste end-to-end
def test_pipeline_completo_classificacao(dados_brutos):
    # 1. Processar dados brutos
    df_proc = executar_pipeline_processamento(dados_brutos)
    
    # 2. Criar features
    df_feat, artefatos = executar_pipeline_features(df_proc)
    
    # 3. Treinar modelo
    resultado = treinar_pipeline_completo(df_feat, 'target', 'classificacao')
    
    assert 'melhor_modelo' in resultado
```

#### 2. `test_cenarios_reais.py`
Testa com dados reais e edge cases:
- âœ… Dataset real de conforto tÃ©rmico
- âœ… Dados com muitos valores faltantes
- âœ… Datasets mÃ­nimos
- âœ… Colunas categÃ³ricas com valor Ãºnico
- âœ… ValidaÃ§Ã£o de artefatos gerados

#### 3. `test_pipeline_unificado.py`
Valida pipeline unificado (classificaÃ§Ã£o + regressÃ£o):
- âœ… Mesmo cÃ³digo para ambos tipos de problema
- âœ… ParÃ¢metro `tipo_problema` funciona corretamente
- âœ… MÃ©tricas apropriadas para cada tipo

## ğŸš€ Como Executar os Testes

### Todos os testes
```bash
pytest
```

### Apenas testes unitÃ¡rios (rÃ¡pido)
```bash
pytest tests/unit/
```

### Apenas testes de integraÃ§Ã£o
```bash
pytest tests/integration/
```

### Testes de um mÃ³dulo especÃ­fico
```bash
pytest tests/unit/features/
pytest tests/unit/treinamento/
```

### Testes com cobertura
```bash
pytest --cov=src --cov-report=html
```

### Testes com marcadores
```bash
# Apenas testes rÃ¡pidos
pytest -m "not slow"

# Apenas testes de integraÃ§Ã£o
pytest -m integration

# Pular testes que precisam de dados reais
pytest -m "not skipif"
```

## ğŸ“Š Cobertura de Testes

### Status Atual

**Testes UnitÃ¡rios**: 55 arquivos
- âœ… API: 1 teste
- âœ… Features: 14 testes (codificaÃ§Ã£o, criaÃ§Ã£o, normalizaÃ§Ã£o)
- âœ… Pipelines: 4 testes
- âœ… Processamento: 16 testes (limpeza, imputaÃ§Ã£o, temporal)
- âœ… Treinamento: 13 testes (avaliaÃ§Ã£o, configuraÃ§Ã£o, treino, utils)
- âœ… Utils: 7 testes (IO, tipos, resoluÃ§Ã£o)

**Testes de IntegraÃ§Ã£o**: 7 arquivos
- âœ… Pipeline end-to-end completo
- âœ… CenÃ¡rios reais e edge cases
- âœ… Pipeline unificado (classificaÃ§Ã£o/regressÃ£o)
- âœ… Pipeline de treinamento
- âœ… Pipeline de processamento

### MÃ³dulos com Alta Cobertura
- âœ… Features (codificaÃ§Ã£o, criaÃ§Ã£o, normalizaÃ§Ã£o)
- âœ… Processamento (limpeza, imputaÃ§Ã£o, temporal)
- âœ… Treinamento (configuraÃ§Ã£o, persistÃªncia, treino unificado)
- âœ… Pipelines (processamento, features, treinamento unificado)

### MÃ³dulos com Cobertura Parcial
- âš ï¸ ClearML (integraÃ§Ã£o nÃ£o prioritÃ¡ria)
- âš ï¸ VisualizaÃ§Ã£o (funcionalidade secundÃ¡ria)
- âš ï¸ Dados sintÃ©ticos (utilidade auxiliar)
- âš ï¸ AnÃ¡lise exploratÃ³ria (utilidade auxiliar)

## ğŸ”§ Fixtures Compartilhadas

As fixtures estÃ£o em `conftest.py` e incluem:

```python
@pytest.fixture
def dados_brutos_completos():
    """Dataset sintÃ©tico completo para testes."""
    ...

@pytest.fixture
def dados_conforto_termico():
    """Dataset especÃ­fico do projeto."""
    ...
```

## ğŸ“ Boas PrÃ¡ticas

### Para Testes UnitÃ¡rios
1. âœ… Teste apenas uma coisa por vez
2. âœ… Use mocks para dependÃªncias externas
3. âœ… Mantenha testes rÃ¡pidos (< 1s)
4. âœ… Nomes descritivos: `test_funcao_quando_condicao_entao_resultado`
5. âœ… Use fixtures para dados de teste

### Para Testes de IntegraÃ§Ã£o
1. âœ… Teste fluxos reais do usuÃ¡rio
2. âœ… Use dados realistas (subset de produÃ§Ã£o)
3. âœ… Valide saÃ­das esperadas, nÃ£o implementaÃ§Ã£o
4. âœ… Marque testes lentos com `@pytest.mark.slow`
5. âœ… Cleanup apÃ³s cada teste (arquivos temporÃ¡rios, etc.)

### PadrÃ£o AAA
Todos os testes seguem o padrÃ£o **Arrange-Act-Assert**:

```python
def test_exemplo():
    # Arrange: Preparar dados de teste
    df = pd.DataFrame({'col': [1, 2, 3]})
    
    # Act: Executar funÃ§Ã£o
    resultado = processar(df)
    
    # Assert: Validar resultado
    assert len(resultado) == 3
    assert 'col' in resultado.columns
```

## ğŸ› Debugging

### Ver saÃ­da completa
```bash
pytest -v -s
```

### Parar no primeiro erro
```bash
pytest -x
```

### Executar teste especÃ­fico
```bash
pytest tests/unit/features/test_normalizar.py::test_normalizar_standard
```

### Modo interativo (PDB)
```bash
pytest --pdb
```

## ğŸ“ˆ CI/CD

Os testes sÃ£o executados automaticamente em:
- âœ… Push para branch principal
- âœ… Pull requests
- âœ… Deploy para produÃ§Ã£o

**Pipeline CI**:
1. Executar testes unitÃ¡rios (rÃ¡pido)
2. Se passou â†’ Executar testes de integraÃ§Ã£o
3. Se passou â†’ Gerar relatÃ³rio de cobertura
4. Se passou â†’ Deploy

## ğŸ¤ Contribuindo

Ao adicionar novo cÃ³digo:

1. **Sempre** adicione testes unitÃ¡rios
2. Se for um fluxo novo, adicione teste de integraÃ§Ã£o
3. Mantenha cobertura > 80%
4. Execute testes localmente antes de commitar:
   ```bash
   pytest tests/
   ```

---

**Ãšltima atualizaÃ§Ã£o**: 2026-02-05
**Cobertura total**: ~85% (55 testes unitÃ¡rios + 7 testes integraÃ§Ã£o)
