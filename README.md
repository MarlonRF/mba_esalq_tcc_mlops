# TCC ClearML - Sistema de Pipeline de Conforto T√©rmico

Projeto completo de pipeline de machine learning para an√°lise de conforto t√©rmico usando PyCaret e ClearML. O sistema implementa processamento de dados, treinamento de modelos e versionamento de datasets com rastreabilidade completa.

‚úÖ Sistema em produ√ß√£o no Google Cloud Platform com CI/CD automatizado
üîß Permiss√µes IAM configuradas para Container Registry gcr.io/streamlit-388123/conforto-api
üì¶ Docker Registry: gcr.io/streamlit-388123/conforto-api

## üìã √çndice

- [Vis√£o Geral](#vis√£o-geral)
- [Funcionalidades](#funcionalidades)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Instala√ß√£o](#instala√ß√£o)
- [Configura√ß√£o ClearML](#configura√ß√£o-clearml)
- [Como Usar](#como-usar)
- [Pipelines Dispon√≠veis](#pipelines-dispon√≠veis)
- [API REST](#api-rest)
- [Configura√ß√µes](#configura√ß√µes)
- [Exemplos de Uso](#exemplos-de-uso)
- [Troubleshooting](#troubleshooting)
- [Contribui√ß√£o](#contribui√ß√£o)

## üéØ Vis√£o Geral

Este projeto implementa um sistema completo de machine learning para an√°lise de dados de conforto t√©rmico, com as seguintes caracter√≠sticas:

- **Pipeline de Processamento**: Limpeza, transforma√ß√£o e feature engineering automatizados
- **Pipeline de Treinamento**: Compara√ß√£o autom√°tica de modelos com PyCaret
- **Versionamento de Datasets**: Controle de vers√£o usando ClearML
- **API REST**: Endpoint para predi√ß√µes em tempo real
- **Gera√ß√£o de Dados Sint√©ticos**: Bootstrap cumulativo para testes
- **Rastreabilidade Completa**: Tracking de experimentos e m√©tricas

## ‚ú® Funcionalidades

### üîÑ Pipeline de Processamento
- Limpeza autom√°tica de dados (valores ausentes, outliers)
- Convers√£o de tipos de dados
- Cria√ß√£o de features derivadas (IMC, Heat Index, Dew Point)
- Normaliza√ß√£o e codifica√ß√£o de vari√°veis categ√≥ricas
- Imputa√ß√£o inteligente de valores faltantes
- Valida√ß√£o de integridade dos dados

### ü§ñ Pipeline de Treinamento
- Compara√ß√£o autom√°tica de m√∫ltiplos algoritmos
- Otimiza√ß√£o de hiperpar√¢metros
- Valida√ß√£o cruzada estratificada
- Gera√ß√£o autom√°tica de gr√°ficos e m√©tricas
- Registro de modelos no ClearML
- Cria√ß√£o autom√°tica de API para predi√ß√µes

### üìä An√°lise e Visualiza√ß√£o
- Relat√≥rios detalhados de performance
- Gr√°ficos de import√¢ncia de features
- Curvas ROC, Precision-Recall e Calibra√ß√£o
- Matriz de confus√£o e m√©tricas detalhadas
- Dashboard interativo no ClearML

### üåê API REST
- Endpoint `/predict` para predi√ß√µes em tempo real
- Valida√ß√£o autom√°tica de entrada
- Documenta√ß√£o autom√°tica com FastAPI
- Modelo carregado em mem√≥ria para alta performance

## üìÅ Estrutura do Projeto (atual)

```
.
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/                # FastAPI + modelo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile      # Build apenas da API
‚îÇ   ‚îî‚îÄ‚îÄ funcoes/            # N√∫cleo de processamento/treino (ClearML/PyCaret)
‚îú‚îÄ‚îÄ tests/                  # Unit e integration
‚îú‚îÄ‚îÄ documentacao/           # Guias e docs
‚îú‚îÄ‚îÄ legacy/                 # Arquivos legados/backup
‚îú‚îÄ‚îÄ pyproject.toml, uv.lock, README.md, pytest.ini
‚îî‚îÄ‚îÄ .github/workflows/      # CI/CD
```

## üöÄ Instala√ß√£o



## üöÄ Instala√ß√£o

### Pr√©-requisitos
- Python 3.11 (PyCaret 3.3.2 n√£o suporta 3.12+)
- Git
- [uv](https://github.com/astral-sh/uv) instalado (recomendado)

### Instala√ß√£o com uv (recomendado)

```bash
# Clone o reposit√≥rio

cd tcc_clm

# Instala depend√™ncias conforme pyproject/uv.lock
uv sync

# Ativa o ambiente virtual gerenciado pelo uv
source .venv/bin/activate  # Linux/Mac
.\.venv\Scripts\Activate   # Windows PowerShell
```

### Instala√ß√£o alternativa com pip

```bash
git clone https://github.com/seu-usuario/tcc_clm.git
cd tcc_clm
python -m venv .venv
source .venv/bin/activate  # ou .\.venv\Scripts\Activate no Windows
pip install -r requirements.txt  # Opcional; preferir uv
```
```
clearml>=1.11.0
pycaret>=3.0.0
pandas>=1.5.0
scikit-learn>=1.3.0
fastapi>=0.100.0
uvicorn>=0.23.0
numpy>=1.24.0
matplotlib>=3.6.0
seaborn>=0.12.0
```

## ‚öôÔ∏è Configura√ß√£o ClearML

### 1. Servidor ClearML

Voc√™ pode usar o servidor ClearML de duas formas:

#### Op√ß√£o A: Servidor Local (Docker)
```bash
# Instalar ClearML Server com Docker
docker run -d --name clearml-server -p 8080:8080 -p 8008:8008 -p 8081:8081 allegroai/clearml-server
```

#### Op√ß√£o B: ClearML Community Server (Gratuito)
1. Registre-se em [app.clear.ml](https://app.clear.ml)
2. Obtenha suas credenciais de API

### 2. Configura√ß√£o de Credenciais

Crie o arquivo `credenciais.json` (este arquivo est√° no .gitignore):

```json
{
  "api_host": "SEU_API_HOST",
  "web_host": "SEU_WEB_HOST", 
  "files_host": "SEU_FILES_HOST",
  "access_key": "SEU_ACCESS_KEY",
  "secret_key": "SEU_SECRET_KEY"
}
```

### 3. Vari√°veis de Ambiente

Crie o arquivo `.env` na raiz do projeto:

```env
# ClearML Configuration
CLEARML_API_HOST=seu_api_host
CLEARML_WEB_HOST=seu_web_host
CLEARML_FILES_HOST=seu_files_host
CLEARML_API_ACCESS_KEY=seu_access_key
CLEARML_API_SECRET_KEY=seu_secret_key

# Project Settings
PROJECT_NAME=conforto_termico
DATASET_PROJECT=Datasets
```

### 4. Configura√ß√£o Inicial

```python
# Execute uma vez para configurar
clearml-init
# Siga as instru√ß√µes na tela
```

## üìñ Como Usar

### 1. Execu√ß√£o Completa via Notebook

O notebook principal `exec_pipelines_completo.ipynb` cont√©m o pipeline completo:

```bash
# Inicie o Jupyter Notebook
jupyter notebook exec_pipelines_completo.ipynb
```

Execute as c√©lulas em sequ√™ncia:
1. Importa√ß√µes e configura√ß√µes
2. Carregamento de dados
3. Pipeline de processamento
4. Pipeline de treinamento
5. Avalia√ß√£o e registro de resultados

### 2. Execu√ß√£o Program√°tica

```python
from funcoes.io_local import load_dataframe
from funcoes.processamento import processar_df, ProcCfg
from funcoes.treinar import treinar_classificacao

# 1. Carregar dados
df = load_dataframe('dados/meus_dados.csv')

# 2. Processar dados
cfg = ProcCfg()  # Configura√ß√£o padr√£o
df_processado, artefatos = processar_df(df, cfg)

# 3. Treinar modelo
params = {
    "data": df_processado,
    "target": "sensacao_termica",
    "session_id": 42,
    "normalize": True,
    "fold": 5,
    "use_gpu": False  # Mude para True se tiver GPU
}

exp, modelo, resultado = treinar_classificacao(params)
```

## üîß Pipelines Dispon√≠veis

### Pipeline de Processamento

**Arquivo**: `pipeline_processamento.py`

**Etapas**:
1. **Limpeza B√°sica**: Remo√ß√£o de valores inv√°lidos
2. **Convers√£o de Tipos**: Aplica√ß√£o do dicion√°rio de tipos
3. **Feature Engineering**: Cria√ß√£o de features derivadas
4. **Imputa√ß√£o**: Preenchimento inteligente de valores faltantes
5. **Normaliza√ß√£o**: Padroniza√ß√£o de vari√°veis num√©ricas
6. **Codifica√ß√£o**: Transforma√ß√£o de vari√°veis categ√≥ricas
7. **Valida√ß√£o**: Verifica√ß√£o de integridade final

### Pipeline de Treinamento

**Arquivo**: `pipeline_treinamento.py`

**Modelos Testados**:
- Logistic Regression
- Random Forest
- Gradient Boosting
- Extra Trees
- AdaBoost
- Naive Bayes
- K-Neighbors
- SVM
- LightGBM
- XGBoost

## üåê API REST

### Inicializa√ß√£o da API

```bash
# Execute a API
python api.py

# Ou com uvicorn diretamente
uvicorn api:app --host 0.0.0.0 --port 8000 --reload
```

### Endpoints Dispon√≠veis

#### GET `/`
Verifica√ß√£o de sa√∫de da API

#### POST `/predict`
Predi√ß√£o de conforto t√©rmico

**Request Body**:
```json
{
  "idade_anos": 30,
  "peso_kg": 70.5,
  "altura_cm": 175.0,
  "sexo_biologico": "m",
  "temperatura_media_c": 25.5,
  "umidade_relativa_percent": 60.0,
  "radiacao_solar_media_wm2": 200.0
}
```

**Response**:
```json
{
  "prediction": "Neutro"
}
```

### Documenta√ß√£o Interativa

Acesse `http://localhost:8000/docs` para documenta√ß√£o autom√°tica Swagger UI.

## üí° Exemplos de Uso

### Exemplo 1: Processamento B√°sico

```python
from funcoes.io_local import load_dataframe
from funcoes.processamento import processar_arquivo, ProcCfg

# Configura√ß√£o customizada
cfg = ProcCfg(
    criar_derivadas=True,
    normalizar=True,
    codificar=True
)

# Processar arquivo
processar_arquivo(
    path_in="dados_brutos.csv",
    path_out="dados_processados.csv",
    cfg=cfg,
    salvar_mapas_em="artefatos/"
)
```

### Exemplo 2: Treinamento Customizado

```python
from funcoes.treinar import treinar_random_forest

resultado = treinar_random_forest(
    dados=df_processado,
    coluna_alvo="sensacao_termica",
    atributos=["idade_anos", "peso_kg", "temperatura_media_c"],
    test_size=0.2,
    random_state=42,
    registrar_clearml=True,
    nome_modelo="rf_conforto_termico"
)

print(f"Acur√°cia: {resultado['metrics']['accuracy']:.3f}")
```

### Exemplo 3: Gera√ß√£o de Dados Sint√©ticos

```python
from funcoes.gerar_dados import gerar_amostras_bootstrap_cumulativas

# Gerar amostras bootstrap
caminhos = gerar_amostras_bootstrap_cumulativas(
    df=df_original,
    tamanhos_cumulativos=[100, 500, 1000, 2000],
    diretorio_saida="dados_sinteticos/",
    prefixo="bootstrap_conforto",
    random_state=42
)
```

## üîç Troubleshooting

### Problemas Comuns

#### 1. Erro de Conex√£o ClearML
**Problema**: `ConnectionError: Could not connect to ClearML server`

**Solu√ß√£o**:
- Verifique se o servidor ClearML est√° rodando
- Confirme as credenciais em `credenciais.json`
- Teste a conectividade de rede

#### 2. Erro de GPU no PyCaret
**Problema**: `GPU device not found, falling back to CPU`

**Solu√ß√£o**:
```python
# Desabilite GPU se n√£o dispon√≠vel
params["use_gpu"] = False
```

#### 3. M√≥dulo n√£o encontrado
**Problema**: `ModuleNotFoundError: No module named 'clearml'`

**Solu√ß√£o**:
```bash
# Reinstale depend√™ncias
pip install -r requirements.txt --force-reinstall
```

### Verifica√ß√£o de Integridade

```bash
# Teste imports
python -c "from funcoes import *; print('Imports OK')"

# Teste ClearML
python -c "from clearml import Task; print('ClearML OK')"

# Teste PyCaret  
python -c "from pycaret.classification import *; print('PyCaret OK')"
```

## üìä M√©tricas e Avalia√ß√£o

### M√©tricas Calculadas

- **Accuracy**: Precis√£o geral do modelo
- **AUC**: √Årea sob a curva ROC
- **Recall**: Taxa de verdadeiros positivos
- **Precision**: Precis√£o por classe
- **F1-Score**: M√©dia harm√¥nica precision/recall
- **Kappa**: Concord√¢ncia entre predito e real
- **MCC**: Coeficiente de correla√ß√£o de Matthews

### Visualiza√ß√µes Geradas

- Curva ROC
- Precision-Recall Curve
- Matriz de Confus√£o
- Feature Importance
- Learning Curves
- Calibration Plots

## ü§ù Contribui√ß√£o

### Como Contribuir

1. **Fork** o reposit√≥rio
2. **Clone** seu fork
3. **Crie** uma branch para sua feature: `git checkout -b feature/nova-feature`
4. **Implemente** suas mudan√ßas
5. **Teste** thoroughly
6. **Commit** com mensagens claras: `git commit -m 'feat: adiciona nova feature'`
7. **Push** para seu fork: `git push origin feature/nova-feature`
8. **Abra** um Pull Request

### Padr√µes de C√≥digo

- **PEP 8**: Siga as conven√ß√µes Python
- **Docstrings**: Documente todas as fun√ß√µes
- **Type Hints**: Use anota√ß√µes de tipo
- **Logging**: Use logging ao inv√©s de print
- **Testes**: Inclua testes para novas features

## üìù Changelog

### v1.0.0 (2024-01-15)
- ‚ú® Pipeline completo de processamento implementado
- ‚ú® Pipeline de treinamento com PyCaret
- ‚ú® Integra√ß√£o completa com ClearML
- ‚ú® API REST funcional
- ‚ú® Gera√ß√£o de dados sint√©ticos
- üìö Documenta√ß√£o completa

### Pr√≥ximas Features
- üîÑ Pipeline de retreinamento autom√°tico
- üìä Dashboard web interativo
- üîî Sistema de alertas e monitoramento
- üöÄ Deploy automatizado

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üôè Agradecimentos

- [PyCaret](https://pycaret.org/) - Framework de ML
- [ClearML](https://clear.ml/) - MLOps platform
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework
- [Pandas](https://pandas.pydata.org/) - Data manipulation

---

‚≠ê **Se este projeto foi √∫til para voc√™, considere dar uma estrela!** ‚≠ê

## üìß Contato

Para d√∫vidas ou sugest√µes, abra uma [issue](https://github.com/seu-usuario/tcc_clm/issues) ou entre em contato atrav√©s do GitHub.

