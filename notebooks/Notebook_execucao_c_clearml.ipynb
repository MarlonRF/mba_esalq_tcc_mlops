{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c066b6ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ead18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml.backend_api.session.client import APIClient\n",
    "client = APIClient()\n",
    "# pegue o projeto pelo nome (ou já use o ID, se souber)\n",
    "#proj = client.projects.get_all(name='teste2')[0]\n",
    "projetos = client.projects.get_all()\n",
    "projetos = {projeto.name:projeto.id for projeto in projetos if projeto}\n",
    "print(projetos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19769771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLOAD\n",
    "upload_dataset(df, dataset_name=\"dados_brutos\", dataset_project=\"Datasets\", description=\"Dataset bruto, sem processamento\"\n",
    "               , tags=[\"conforto_termico\", \"santa_maria\", \"brasil\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3520d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    id=projetos['conforto_termddico']   \n",
    "except:\n",
    "    id=client.projects.create(name='conforto_termico').id\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9baa344",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.projects.delete(project=proj.id, force=True)  # falha se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_datasets=Dataset.list_datasets()\n",
    "pd.DataFrame(lista_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cdb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD\n",
    "df= download_from_clearml('a155cb8c8a7f4d89b99bd05ce70cfd41', 'dados/baixados/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18397894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe as funções do seu script de pipeline\n",
    "from pipeline_de_treinamento import step_treinar_modelo, step_avaliar_e_registrar_modelo\n",
    "\n",
    "# Suponha que 'df_processado' é seu DataFrame pronto\n",
    "# df_processado = ...\n",
    "df_processado = df_processado.iloc[:300]\n",
    "print(\"--- Testando a etapa de treino ---\")\n",
    "try:\n",
    "    # Use .__wrapped__ para chamar a função interna diretamente\n",
    "    artefatos = step_treinar_modelo.__wrapped__(df_treino=df_processado)\n",
    "    print(\"Etapa de treino funcionou. Artefatos gerados:\")\n",
    "    print(artefatos)\n",
    "\n",
    "    print(\"\\n--- Testando a etapa de avaliação ---\")\n",
    "    # Agora teste a segunda etapa com os artefatos da primeira\n",
    "    step_avaliar_e_registrar_modelo.__wrapped__(artefatos_treino=artefatos, df_treino=df_processado)\n",
    "    print(\"Etapa de avaliação funcionou.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n!!! Erro encontrado durante o teste local !!!\")\n",
    "    # Isso imprimirá o erro real imediatamente, sem o ClearML no meio.\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
